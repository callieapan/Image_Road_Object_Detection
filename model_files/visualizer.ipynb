{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_nn import *\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = [15, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27af812592264669a081bb856822c1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='cam', options=('CAM_FRONT.jpeg', 'CAM_FRONT_LEFT.jpeg', 'CAM_BACK_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_folder = 'data'\n",
    "annotation_csv = 'data/annotation.csv'\n",
    "downsample_shape = (100,100)\n",
    "\n",
    "unlabeled_scene_index = np.arange(106)\n",
    "labeled_scene_index = np.arange(106, 134)\n",
    "    \n",
    "normalize = torchvision.transforms.Normalize(mean=[0.6394939, 0.6755114, 0.7049375],\n",
    "                                     std=[0.31936955, 0.3117349 , 0.2953726 ])\n",
    "\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                           normalize\n",
    "                                           ])\n",
    "train_labeled_scene_index, val_labeled_scene_index = gen_train_val_index(labeled_scene_index)\n",
    "\n",
    "\n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "\n",
    "    \n",
    "denormer = UnNormalize(mean=[0.6394939, 0.6755114, 0.7049375],std=[0.31936955, 0.3117349 , 0.2953726 ])    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def get_batch_loader(cam):\n",
    "    labeled_trainset = TriangleLabeledDataset(image_folder=image_folder,\n",
    "                                      annotation_file=annotation_csv,\n",
    "                                      scene_index=val_labeled_scene_index,\n",
    "                                      transform=transform,\n",
    "                                      extra_info=True,\n",
    "                                    camera = cam,downsample_shape=downsample_shape)\n",
    "    val_loader = torch.utils.data.DataLoader(labeled_trainset , batch_size=2, \n",
    "                                          shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
    "\n",
    "    return val_loader\n",
    "\n",
    "def plot_image(ax,image,title,**kw_imshow):\n",
    "\n",
    "    ax.imshow(image,**kw_imshow);\n",
    "    ax.set_title(title)\n",
    "    return ax\n",
    "\n",
    "\n",
    "@interact(cam=image_names,num_samples=fixed(2))\n",
    "def show_pred_v_target(cam,num_samples=1):\n",
    "    loader = get_batch_loader(cam)\n",
    "    model = load_cam_model(cam,latest_fe=True,cloud=False)\n",
    "    train_loader = get_batch_loader(cam)\n",
    "    for i in range(num_samples):\n",
    "        sample, target, road_image, extra, road_image_mod = iter(train_loader).next()\n",
    "        pred = model(torch.stack(sample))[0]> 0.5\n",
    "        msk = load_mask(cam,(100,100))\n",
    "        orig_image = road_image[0].numpy()*msk\n",
    "        pred_image = orig_image.copy()\n",
    "        pred_image[msk] = pred\n",
    "        fig, axs = plt.subplots(1,3)\n",
    "        plot_image(axs[0],denormer(sample[0]).numpy().transpose(1, 2, 0),\"Input\")\n",
    "        plot_image(axs[1],orig_image,\"Target\",cmap='binary')\n",
    "        plot_image(axs[2],pred_image,\"Predicted\",cmap='binary')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, target, road_image, extra, road_image_mod = iter(get_batch_loader(image_names[0])).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 306])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
